#! /usr/bin/env python
# encoding: utf-8
#
# Tool to read out and examine images generated by the sdlogger
#
# Copyright 2013 Andreas Messer <andi@bastelmap.de>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys
import struct

import numpy as np
import argparse
import tempfile
import re

from operator import itemgetter


class SDLoggerPDU(object):
    blocktypes = 'invalid config data calibration'.split()
    channelids = 'ch0 ch1 ch2 ch3 ch0-ch1 ch1-ch0 ch2-ch3 ch3-ch2 di'.split()

    class InvalidPduType(Exception):
      def __init__(self,got, expected):
        super(SDLoggerPDU.InvalidPduType,self).__init__()
        self.got, self.expected = got,expected
      
      def __str__(self):
        return 'Invalid Pdu Type %u. Expected %u' % (got, expected)
        
    @classmethod
    def getBlockId(cls, name):
        return cls.blocktypes.index(name)

    @classmethod
    def getChannelId(cls, name):
        return cls.channelids.index(name)
    
    @classmethod
    def readPduHead(cls,file,pdu = None):
      type,length = struct.unpack("<2B",file.read(2))
      
      if type != cls.getBlockId(pdu):
        raise cls.InvalidPduType(type,cls.getBlockId(pdu))
    
      return type,length

    @classmethod
    def writePduHead(cls,file,pdu, length):
      return file.write(struct.pack("<2B", cls.getBlockId(pdu), length))  

    
    def __init__(self,**kwargs):
      super(SDLoggerPDU,self).__init__()  
      self.__dict__.update(kwargs)  
      
    def writeConfigPdu(self,file):
        fields = '<2B H %uB B' % len(self.channels)
        values = (self.getBlockId('config'), struct.calcsize(fields) - 3, self.interval) \
                 + tuple(map(self.getChannelId, self.channels)) \
                 + (0xFF,)
                 
        return file.write(struct.pack(fields,*values))

    def writeCalibrationPdu(self,file):
      return self.writePduHead(file, 'calibration',2) + file.write(struct.pack('<HB',self.reference,0xFF))
    
    def readConfigPdu(self,file):
      type,length = self.readPduHead(file, 'config')    
        
      nchan = (length - 2) / 1
          
      x = struct.unpack("<H %uB x" % nchan, file.read(length + 1))
    
      self.interval = x[0]
      self.channels = itemgetter(*x[1:])(self.channelids)
    
      return length + 3
    
    def readCalibrationPdu(self,file):
      type,length = self.readPduHead(file, 'calibration')    
        
      self.reference, = struct.unpack("<H x", file.read(length + 1))
    
      return length + 3


class DatasetEvaluatorIterator(object):
    blocksize = 4096

    def __init__(self,file, columns, tstep, tstart = None, tend = None):

        pdu = SDLoggerPDU()
        pdu.readConfigPdu(file)
        file.seek(512)
        pdu.readCalibrationPdu(file)

        dtype = np.dtype ([
          ('type',   '<u1'),
          ('length', '<u1'),
          ('ts',     '<u4'),
          ('data',   '<u2', (len(pdu.channels),)),
          ('end',    '<u1'),
        ])

        self.file      = file
        self.tstep     = np.uint32(tstep)
        self.tend      = np.uint32(tend or 0xFFFFFFFF)
        self.dtype     = dtype
        self.reference = np.float32(pdu.reference) / np.float32(1000)
        self.channels  = pdu.channels
        self.interval  = np.uint16(pdu.interval)
        self.chunklist   = []
        self.columns   = columns
        self.cache     = {}

        # read data until first aligned block boundary
        bytes_to_read = ((file.tell() / self.blocksize) + 1) * self.blocksize - file.tell()
        while bytes_to_read % dtype.itemsize:
            bytes_to_read += self.blocksize

        self.bufshape = (bytes_to_read / dtype.itemsize)
        self.readChunk()

        # calculate read chunk size
        chunksize = self.blocksize
        while chunksize <  (tstep * dtype.itemsize / int(self.interval)):
            chunksize += self.blocksize

        while chunksize % dtype.itemsize:
            chunksize += self.blocksize

        self.bufshape = (chunksize / dtype.itemsize)

        if not self.chunklist:
            self.readChunk()

        self.tstart = np.uint32(tstart or ((np.min(self.chunklist[0]['ts'][0,...]) / self.tstep) * self.tstep))


    def readChunk(self):
        buf = np.ndarray(shape=self.bufshape, dtype=self.dtype)
        bytes_read = self.file.readinto(buf)

        buf = buf[0:bytes_read / self.dtype.itemsize]

        try:
            last_index = np.min(np.nonzero(buf['type'] != 2))
            buf = buf[0:last_index]
            del self.file
        except ValueError:
            pass
        
        ts            = buf['ts']
        data          = np.atleast_2d(np.transpose(buf['data']))
        ts_correction = (data & 0xF000) >> 12
        
        mask_overflow = ts_correction < (ts & 0xF)
        ts_correction[np.nonzero(mask_overflow)] += 0x10

        chunk = { 
            'ts'       : ts_correction | (ts & 0xFFFFFFF0),
            'data'     : data & 0x0FFF,
        }

        self.chunklist.append(chunk)

    def __iter__(self):
        return self

    def next(self):

        # drop all outdated chunks
        l = self.chunklist
        while True:
            if l and np.all(l[0]['ts'][:,-1] < self.tstart):
                l.pop(0)
            elif l and np.all(l[-1]['ts'][:,-1] >= (self.tstart + self.tstep)):
                break
            elif getattr(self,'file',None):
               self.readChunk()
            else:
               break
            
        if not self.chunklist or self.tstart >= self.tend:
            raise StopIteration()

        result     = tuple(eval(x,{},self) for x in self.columns)
        self.cache = {}

        # advance to next time step
        self.tstart = self.tstart + self.tstep

        return result

    def __getitem__(self,key):
        m = re.match(r"^(ts|data)(\d+)?$", key)

        if key in self.cache:
            obj = self.cache[key]
        elif m:
            field, lane = m.group(1,2)

            arrlist = []
            
            if lane:
                getSlice = lambda inp : inp[int(lane),:][np.newaxis,...]
            else:
                getSlice = lambda inp : inp

            tstart_last = self.tstart

            if not self.chunklist:
                raise Exception()

            for x in self.chunklist:
                ts        = getSlice(x['ts'])
                cond      = (ts >= self.tstart) & (ts < (self.tstart + self.tstep))
                values    = np.compress(np.any(cond,axis=0), getSlice(x[field]), axis=1)

                arrlist.append(values)

            obj = np.hstack(arrlist)

            if field == 'ts':
                obj = np.asarray(obj,dtype=np.float32) / np.float32(1000) 
            elif field == 'data':
                obj = np.asarray(obj,dtype=np.float32) * self.reference / np.float32(4096)

            self.cache[key] = obj
        elif key == 'tstart':
            obj = self.tstart / np.float32(1000)
        elif key == 'tstep':
            obj = self.tstep / np.float32(1000)
        else:
            try:
                obj = getattr(np, key)
            except AttributeError:
                raise KeyError()

        return obj

def dump(file, columns, **kw):
    for cols in DatasetEvaluatorIterator(file, columns, **kw):
        chunk = np.transpose(np.vstack(np.atleast_2d(x) for x in cols))
        np.savetxt(sys.stdout, chunk, fmt="%.4f")

def plot(file, items, **kw):
    import matplotlib.pyplot as plt
    
    colors   = "rgby"
    linetype = "-"

    data = tuple(x for x in DatasetEvaluatorIterator(file, items, **kw))

    plotlist = []

    for index, expr in enumerate(items):
        xdata = np.atleast_2d(np.hstack(tuple(chunk[index][0] for chunk in data)))
        ydata = np.atleast_2d(np.hstack(tuple(chunk[index][1] for chunk in data)))
       
        plotlist += [xdata[0,:],ydata[0,:], colors[index] + linetype]

    del data

    plt.plot(*tuple(plotlist))
    plt.show()

def config(file, interval, channels):
    file.seek(0,2)
    filesize = file.tell()
    file.seek(0,0)

    sys.stdout.write('Card Size is %0.1f MB.\n' % (filesize/1024./1024.))
    
    pdu = SDLoggerPDU()
    pdu.interval = interval
    pdu.channels = channels
    
    sys.stdout.write('Writing Configuration...')
    blocksize = 4096
    len = pdu.writeConfigPdu(file)
    
    empty = b'\xff' * blocksize
    
    len += file.write(empty[0:blocksize - len])

    sys.stdout.write(' done.\n')
    
    sys.stdout.write('Initializing Card... ')
    sys.stdout.flush()
    
    filesize = min(filesize,1024)
    progress = 0
    while len < filesize:
      len += file.write(empty[0:min(blocksize,filesize-len)])
      if int(10 * len / filesize) > progress:
        progress = int(10 * len / filesize)
        sys.stdout.write('#')
        sys.stdout.flush()

    file.flush()
    
    sys.stdout.write(' done.\n')
        
def main():
  parser = argparse.ArgumentParser(description='SDLogger Image File Tool')
  subparsers = parser.add_subparsers(help='sub-command help')
  
  p = subparsers.add_parser('dump', help='dump records')
  p.add_argument('--tstep',   type=int, default=1000, help='stepping time in ms')
  p.add_argument('--tstart',  type=int, help='stepping start time in ms')
  p.add_argument('--tend',  type=int, help='stepping end time in ms')
  p.add_argument('file',    type=argparse.FileType('rb'))
  p.add_argument('columns', metavar='column', type=str, nargs='+', help='column definition')
  p.set_defaults(func=dump)

  p = subparsers.add_parser('plot', help='generate a plot')
  p.add_argument('--tstep',   type=int, default=1000, help='stepping time in ms')
  p.add_argument('--tstart',  type=int, help='stepping start time in ms')
  p.add_argument('--tend',  type=int, help='stepping end time in ms')
  p.add_argument('file',    type=argparse.FileType('rb'))
  p.add_argument('items', metavar='item', type=str, nargs='+', help='plot definition')
  p.set_defaults(func=plot)
  
  p = subparsers.add_parser('config', help='generate configuration')
  p.add_argument('file', type=argparse.FileType('wb'))
  p.add_argument('interval', type=int, help='sample interval in ms. (1 to 60000)')
  p.add_argument('channels', metavar='channel', type=str, nargs='+', help='channel to sample. (%s)' % ', '. join(SDLoggerPDU.channelids))
  p.set_defaults(func=config)

  args   = parser.parse_args()
  kwargs = dict(vars(args))
  
  try:
    del kwargs['func']
  except KeyError:
    parser.print_help()
    sys.exit(-1)

  args.func(**kwargs)
  
if __name__ == '__main__':
  main()
